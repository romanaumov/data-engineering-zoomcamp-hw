{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07de9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da99a6e7-437c-4ca9-923f-a7e628a13988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca5bbb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/03/08 07:37:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b627abf3-455b-4e03-8c58-27a66c5d7b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-08 07:43:02--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet\n",
      "52.85.39.153, 52.85.39.117, 52.85.39.97, ...ci6vzurychx.cloudfront.net)... \n",
      "connected. to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|52.85.39.153|:443... \n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 64346071 (61M) [binary/octet-stream]\n",
      "Saving to: ‘yellow_tripdata_2024-10.parquet’\n",
      "\n",
      "yellow_tripdata_202 100%[===================>]  61.36M  19.4MB/s    in 3.3s    \n",
      "\n",
      "2025-03-08 07:43:06 (18.5 MB/s) - ‘yellow_tripdata_2024-10.parquet’ saved [64346071/64346071]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51fefa9f-5af9-4812-bad7-278c1ee6e924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254534 yellow_tripdata_2024-10.parquet\n"
     ]
    }
   ],
   "source": [
    "!wc -l yellow_tripdata_2024-10.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "931021a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .parquet('yellow_tripdata_2024-10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d44b7839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', IntegerType(), True), StructField('tpep_pickup_datetime', TimestampType(), True), StructField('tpep_dropoff_datetime', TimestampType(), True), StructField('passenger_count', LongType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', LongType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('payment_type', LongType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('Airport_fee', DoubleType(), True)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c270d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7796c2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.write.parquet('yellow/4/2024/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3cab876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('yellow/4/2024/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "203b5627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d24840a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ab1ca44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       2| 2024-10-10 10:34:57|  2024-10-10 10:53:48|              1|          3.4|         1|                 N|         140|          74|           1|       20.5|  0.0|    0.5|      0.24|         0.0|                  1.0|       24.74|                 2.5|        0.0|\n",
      "|       2| 2024-10-08 21:14:57|  2024-10-08 21:47:02|              2|         5.22|         1|                 N|         166|         107|           1|       31.7|  1.0|    0.5|      7.34|         0.0|                  1.0|       44.04|                 2.5|        0.0|\n",
      "|       2| 2024-10-05 18:29:00|  2024-10-05 18:55:30|              1|         5.29|         1|                 N|          79|         255|           1|       28.9|  0.0|    0.5|       0.1|        6.94|                  1.0|       39.94|                 2.5|        0.0|\n",
      "|       2| 2024-10-04 19:13:00|  2024-10-04 19:35:18|              1|         5.42|         1|                 N|          48|         263|           1|       27.5|  2.5|    0.5|      3.74|         0.0|                  1.0|       37.74|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 11:43:18|  2024-10-01 11:47:40|              1|          0.5|         1|                 N|         142|         239|           1|        5.8|  2.5|    0.5|      1.95|         0.0|                  1.0|       11.75|                 2.5|        0.0|\n",
      "|       2| 2024-10-05 14:04:12|  2024-10-05 14:31:41|              1|         3.61|         1|                 N|         262|         107|           1|       26.8|  0.0|    0.5|       4.0|         0.0|                  1.0|        34.8|                 2.5|        0.0|\n",
      "|       2| 2024-10-05 18:19:44|  2024-10-05 18:25:57|              1|         1.15|         1|                 N|         236|         239|           1|        8.6|  0.0|    0.5|      2.52|         0.0|                  1.0|       15.12|                 2.5|        0.0|\n",
      "|       2| 2024-10-07 15:35:26|  2024-10-07 16:07:25|              3|         4.21|         1|                 N|         236|         113|           1|       29.6|  0.0|    0.5|      6.72|         0.0|                  1.0|       40.32|                 2.5|        0.0|\n",
      "|       2| 2024-10-02 07:24:39|  2024-10-02 07:41:08|              1|          2.5|         1|                 N|         234|         143|           1|       17.0|  0.0|    0.5|       4.2|         0.0|                  1.0|        25.2|                 2.5|        0.0|\n",
      "|       1| 2024-10-02 15:48:49|  2024-10-02 15:58:14|              1|          1.2|         1|                 N|         143|         246|           1|       10.0|  2.5|    0.5|       2.8|         0.0|                  1.0|        16.8|                 2.5|        0.0|\n",
      "|       2| 2024-10-02 09:46:32|  2024-10-02 09:50:30|              1|         0.64|         1|                 N|         239|         142|           1|        5.8|  0.0|    0.5|      1.96|         0.0|                  1.0|       11.76|                 2.5|        0.0|\n",
      "|       1| 2024-10-10 19:55:58|  2024-10-10 20:07:37|              1|          1.5|         1|                 N|         161|         237|           1|       10.7|  5.0|    0.5|      3.45|         0.0|                  1.0|       20.65|                 2.5|        0.0|\n",
      "|       1| 2024-10-04 14:57:46|  2024-10-04 15:12:16|              1|          1.9|         1|                 N|         125|         186|           1|       14.9|  2.5|    0.5|      3.75|         0.0|                  1.0|       22.65|                 2.5|        0.0|\n",
      "|       2| 2024-10-03 15:03:30|  2024-10-03 15:12:50|              1|          0.8|         1|                 N|         140|         229|           2|       10.0|  0.0|    0.5|       0.0|         0.0|                  1.0|        14.0|                 2.5|        0.0|\n",
      "|       2| 2024-10-05 23:06:59|  2024-10-05 23:14:11|              1|         0.96|         1|                 N|         161|         162|           1|        7.9|  1.0|    0.5|      2.58|         0.0|                  1.0|       15.48|                 2.5|        0.0|\n",
      "|       1| 2024-10-04 21:04:30|  2024-10-04 21:15:53|              1|          2.5|         1|                 N|          79|         141|           1|       12.8|  3.5|    0.5|      3.55|         0.0|                  1.0|       21.35|                 2.5|        0.0|\n",
      "|       2| 2024-10-04 14:59:15|  2024-10-04 15:08:10|              1|         1.51|         1|                 N|         142|          43|           1|       10.7|  0.0|    0.5|      2.94|         0.0|                  1.0|       17.64|                 2.5|        0.0|\n",
      "|       2| 2024-10-10 12:24:41|  2024-10-10 12:38:29|              1|         0.87|         1|                 N|         237|         229|           1|       12.8|  0.0|    0.5|      3.36|         0.0|                  1.0|       20.16|                 2.5|        0.0|\n",
      "|       2| 2024-10-04 21:53:44|  2024-10-04 21:59:30|              1|         0.72|         1|                 N|         163|         142|           1|        7.2|  1.0|    0.5|      2.44|         0.0|                  1.0|       14.64|                 2.5|        0.0|\n",
      "|       1| 2024-10-08 19:14:09|  2024-10-08 19:18:27|              0|          0.5|         1|                 N|         230|         186|           2|        5.8|  5.0|    0.5|       0.0|         0.0|                  1.0|        12.3|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d8ad249-2d69-4c85-a412-d4986bba464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+------------+\n",
      "|tpep_pickup_date|PULocationID|DOLocationID|\n",
      "+----------------+------------+------------+\n",
      "|      2024-10-10|         140|          74|\n",
      "|      2024-10-08|         166|         107|\n",
      "|      2024-10-05|          79|         255|\n",
      "|      2024-10-04|          48|         263|\n",
      "|      2024-10-01|         142|         239|\n",
      "|      2024-10-05|         262|         107|\n",
      "|      2024-10-05|         236|         239|\n",
      "|      2024-10-07|         236|         113|\n",
      "|      2024-10-02|         234|         143|\n",
      "|      2024-10-02|         143|         246|\n",
      "|      2024-10-02|         239|         142|\n",
      "|      2024-10-10|         161|         237|\n",
      "|      2024-10-04|         125|         186|\n",
      "|      2024-10-03|         140|         229|\n",
      "|      2024-10-05|         161|         162|\n",
      "|      2024-10-04|          79|         141|\n",
      "|      2024-10-04|         142|          43|\n",
      "|      2024-10-10|         237|         229|\n",
      "|      2024-10-04|         163|         142|\n",
      "|      2024-10-08|         230|         186|\n",
      "+----------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('tpep_pickup_date', F.to_date(df.tpep_pickup_datetime)) \\\n",
    "    .select('tpep_pickup_date', 'PULocationID', 'DOLocationID') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96cd56cd-9d73-481e-8017-f16874595c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:===========================================>              (3 + 1) / 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|tpep_pickup_date| count|\n",
      "+----------------+------+\n",
      "|      2024-10-24|137337|\n",
      "|      2024-10-02|113906|\n",
      "|      2009-01-01|     1|\n",
      "|      2024-10-25|136066|\n",
      "|      2024-10-22|121106|\n",
      "|      2024-10-18|133213|\n",
      "|      2024-10-08|121402|\n",
      "|      2024-10-10|143206|\n",
      "|      2024-10-20|117129|\n",
      "|      2024-10-01|119118|\n",
      "|      2024-10-04|112431|\n",
      "|      2024-10-15|128893|\n",
      "|      2024-10-28|110595|\n",
      "|      2024-10-29|126931|\n",
      "|      2024-10-17|136330|\n",
      "|      2024-10-31|129394|\n",
      "|      2024-10-07|102014|\n",
      "|      2024-11-01|    26|\n",
      "|      2024-10-11|128821|\n",
      "|      2024-10-16|134891|\n",
      "+----------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('tpep_pickup_date', F.to_date(df.tpep_pickup_datetime)) \\\n",
    "    .groupBy('tpep_pickup_date') \\\n",
    "    .count() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "faaf0cbd-0f14-4709-992d-a44c84a29d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('trips_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97a1f24a-9581-4897-8553-810b9366ded4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|number_records|\n",
      "+--------------+\n",
      "|        128893|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_trips_count = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT(1) AS number_records\n",
    "FROM\n",
    "    trips_data\n",
    "WHERE\n",
    "    tpep_pickup_datetime >= '2024-10-15 00:00:00' and\n",
    "    tpep_pickup_datetime < '2024-10-16 00:00:00'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c396f39-8066-414d-ac88-3ff3f6c02a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:>                                                         (0 + 4) / 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|trip_hours|\n",
      "+----------+\n",
      "|162.617778|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_longest_trip = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    (UNIX_TIMESTAMP(tpep_dropoff_datetime) - UNIX_TIMESTAMP(tpep_pickup_datetime)) / 3600.0 AS trip_hours\n",
    "FROM \n",
    "    trips_data\n",
    "ORDER BY \n",
    "    trip_hours DESC\n",
    "LIMIT 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9542a45-7e54-477f-a2a0-828dac7dd710",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locations = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52df8cec-d6fd-40d5-8112-13208060bad7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "path file:/home/ubuntu/data/data-engineering-zoomcamp/05-batch/code/zones already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_locations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzones\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/readwriter.py:1140\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m-> 1140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: path file:/home/ubuntu/data/data-engineering-zoomcamp/05-batch/code/zones already exists."
     ]
    }
   ],
   "source": [
    "df_locations.write.parquet('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe4427e3-917b-469b-9950-6a17bd9bdf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locations.registerTempTable('locations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7a7d37a-ca13-47f1-89e2-1fba6ba2c656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|         pickup_zone|pickup_count|\n",
      "+--------------------+------------+\n",
      "|Governor's Island...|           1|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "least_frequent_zone = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    z.Zone AS pickup_zone, \n",
    "    COUNT(t.PULocationID) AS pickup_count\n",
    "FROM trips_data t\n",
    "JOIN locations z\n",
    "ON t.PULocationID = z.LocationID\n",
    "GROUP BY z.Zone\n",
    "ORDER BY pickup_count ASC\n",
    "LIMIT 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b0e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
